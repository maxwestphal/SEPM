% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/infer.R
\name{infer}
\alias{infer}
\title{Hypothesis testing regarding model performances}
\usage{
infer(estimation, method = "maxT", transform = "none", seed = 1)
}
\arguments{
\item{estimation}{object of class SEPM.estimation (see \code{\link{estimate}}).}

\item{method}{character; specify the (multiple) test used (default: "maxT", currently the only choice)}

\item{transform}{character; specify a known transform, e.g. "none" (default), "logit" or
"asin.sqrt". Alternativly a object of class SEPM.transform created via
\code{\link{define_transform}}).}

\item{seed}{integer; specify the random seed. For reproducibility, this should NOT be changed.}
}
\value{
An SEPM.evaluation object, including inference results, parameters estimates and
hypothesis.
}
\description{
This functions allows hypothesis testing regarding a hypothesis system based on some previously
derived parameter estimates (see \code{\link{estimate}}).
}
\details{
The overall goal is control of the type 1 error rate (rate of false positive claims over
hypothetical repetitions of the evaluation study).
Hence, this function is NOT designed for 'trial and error'!
Iterating over different models, performance measures, benchmarks etc. will surely lead to
an increased rate of errouneous conclusions drawn from the evaluation study. Ideally, this
function should only called once per evaluation study. The provided examples may be helpful to
learn how to call this function correctly.

The random seed is controlled explicitly (and set to 1 by default). The reason for this is the
slight dependence of some internal functions on the random seed (e.g. qmvnorm). Hence different
seeds give (slightly) different results. Thus seed should NOT be changed (unless, for some reason,
numerical issues are encountered).
}
\examples{
set.seed(1)
y <- rep(0:1, each=100)
yhat <- sapply(seq(0.7, 0.9, 0.05),
 function(p){ifelse(rbinom(200, 1, p)==1, y, 1-y)})
e <- define.hypothesis("accuracy", 0.8) \%>\%
 compare(predictions=yhat, labels=y) \%>\%
 estimate() \%>\% test()
summary(e)
}
